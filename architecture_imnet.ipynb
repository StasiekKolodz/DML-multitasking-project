{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9LxlKFFM6AOr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from fastai.vision.learner import create_body\n",
    "from torchvision.models.resnet import resnet18\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import color # For rgb2la & lab2rgb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_colab = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEcDUoeo6AOs",
    "outputId": "1aab2570-c31c-4dde-b4c3-ddb4c8343349"
   },
   "outputs": [],
   "source": [
    "# !pip install fastai==2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "iXEbl2Jl6AOs",
    "outputId": "0901a68f-ff92-492b-d859-6779899ed649"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 256\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z5a6Yh16AOt"
   },
   "source": [
    "Although we are using the same dataset and number of training samples, the exact 8000 images that you train your model on may vary (although we are seeding!) because the dataset here has only 20000 images with different ordering while I sampled 10000 images from the complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_kgV6QE6AOt"
   },
   "source": [
    "### 1.2- Making Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4BcEvlN6AOt"
   },
   "source": [
    "I hope the code is self-explanatory. I'm resizing the images and flipping horizontally (flipping only if it is training set) and then I read an RGB image, convert it to Lab color space and separate the first (grayscale) channel and the color channels as my inputs and targets for the models  respectively. Then I'm making the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UdG8okFr6AOt"
   },
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((IMG_SIZE, IMG_SIZE),  Image.BICUBIC),\n",
    "                # (Train-only) data augmentation\n",
    "                # TODO: Try different variants?\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "            ])\n",
    "        elif split == 'val':\n",
    "            self.transforms = transforms.Resize((IMG_SIZE, IMG_SIZE),  Image.BICUBIC)\n",
    "\n",
    "        self.split = split\n",
    "        self.paths = paths\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.paths[idx]\n",
    "        img_rgb = Image.open(img_path).convert(\"RGB\")\n",
    "        img_rgb = self.transforms(img_rgb)\n",
    "        img_rgb = np.array(img_rgb)\n",
    "        img_lab = color.rgb2lab(img_rgb).astype(\"float32\")\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        # TODO: Understand this (why not use a Torch transform?)\n",
    "        L  = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n",
    "        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n",
    "        \n",
    "        # Store L and ab channels, as well as class\n",
    "        return { 'L': L, 'ab': ab, 'class': self.map_class(img_path.split('/')[-2]) }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "        \n",
    "    def map_class(self, cls):\n",
    "        if cls=='sea_anemone':\n",
    "            return 0\n",
    "        if cls=='pufferfish':\n",
    "            return 1\n",
    "        if cls=='sea_cucumber':\n",
    "            return 2\n",
    "        if cls=='sea_snake':\n",
    "            return 3\n",
    "        if cls=='lionfish':\n",
    "            return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vT8a0h1n6AOt",
    "outputId": "cb544a06-860a-40da-864f-674a15b37c00",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6500 samples · 407 batches\n",
      "Val: 250 samples · 16 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/conda/envs/dml/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_paths = []\n",
    "val_paths = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(DATA_DIR + \"/train\"):\n",
    "    if len(files) == 0: continue\n",
    "    for file in files:\n",
    "        if file.endswith('.JPEG'):\n",
    "            train_paths.append(subdir + \"/\" + file)\n",
    "\n",
    "for subdir, dirs, files in os.walk(DATA_DIR + \"/val\"):\n",
    "    if len(files) == 0: continue\n",
    "    for file in files:\n",
    "        if file.endswith('.JPEG'):\n",
    "            val_paths.append(subdir + \"/\" + file)\n",
    "\n",
    "train_dataset = ColorizationDataset(train_paths, split='train')\n",
    "val_dataset   = ColorizationDataset(val_paths,   split='val')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True, shuffle=True)\n",
    "val_dataloader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True, shuffle=True)\n",
    "\n",
    "print(\"Train:\", len(train_dataset), \"samples ·\", len(train_dataloader), \"batches\")\n",
    "print(\"Val:\", len(val_dataset), \"samples ·\", len(val_dataloader), \"batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 256, 256]) torch.Size([16, 2, 256, 256]) tensor([4, 4, 2, 0, 1, 4, 2, 0, 0, 3, 2, 4, 4, 4, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: looks good!\n",
    "for batch in train_dataloader:\n",
    "    print(batch['L'].shape, batch['ab'].shape, batch['class'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXyg4xn46AOu"
   },
   "source": [
    "### 1.4- Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24CXUhsa6AOy"
   },
   "source": [
    "The architecture of our discriminator is rather straight forward. This code implements a model by stacking blocks of Conv-BatchNorm-LeackyReLU to decide whether the input image is fake or real. Notice that the first and last blocks do not use normalization and the last block has no activation function (it is embedded in the loss function we will use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dMLCHETL6AOy"
   },
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n",
    "                          for i in range(n_down)] # the 'if' statement is taking care of not using\n",
    "                                                  # stride of 2 for the last block in this loop\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n",
    "                                                                                             # activation for the last layer of the model\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9uzQuQC6AOy"
   },
   "source": [
    "Let's take a look at its blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGbzVw4d6AOy",
    "outputId": "aa7bdfb0-eb54-419d-ae25-e44d09b6e19c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchDiscriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PatchDiscriminator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGaWHkKf6AOy"
   },
   "source": [
    "And its output shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sW7a5slT6AOy",
    "outputId": "bf563601-8330-419e-9bb8-d2e1d8984bbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 30, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = PatchDiscriminator(3)\n",
    "dummy_input = torch.randn(16, 3, 256, 256) # batch_size, channels, size, size\n",
    "out = discriminator(dummy_input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OegylkQ6AOz"
   },
   "source": [
    "### 1.5- GAN Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlLTuriJ6AOz"
   },
   "source": [
    "This is a handy class we can use to calculate the GAN loss of our final model. In the __init__ we decide which kind of loss we're going to use (which will be \"vanilla\" in our project) and register some constant tensors as the \"real\" and \"fake\" labels. Then when we call this module, it makes an appropriate tensor full of zeros or ones (according to what we need at the stage) and computes the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JZtfZFNb6AOz"
   },
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        if gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "\n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "\n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMgcRpT56AOz"
   },
   "source": [
    "### 1.x Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "498014en6AOz"
   },
   "source": [
    "In the TowardsDataScince article, I didn't explain this function. Here is our logic to initialize our models. We are going to initialize the weights of our model with a mean of 0.0 and standard deviation of 0.02 which are the proposed hyperparameters in the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4DQhzu1c6AOz"
   },
   "outputs": [],
   "source": [
    "def init_weights(net, init='norm', gain=0.02):\n",
    "\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialized with {init} initialization\")\n",
    "    return net\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhKDBYl46AO0"
   },
   "source": [
    "### 1.6- Putting everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrl9leDI6AO0"
   },
   "source": [
    "This class brings together all the previous parts and implements a few methods to take care of training our complete model. Let's investigate it.\n",
    "\n",
    "In the __init__ we define our generator and discriminator using the previous functions and classes we defined and we also initialize them with init_model function which I didn't explain here but you can refer to my GitHub repository to see how it works. Then we define our two loss functions and the optimizers of the generator and discriminator.\n",
    "\n",
    "The whole work is being done in optimize method of this class. First and only once per iteration (batch of training set) we call the module's forward method and store the outputs in fake_color variable of the class.\n",
    "\n",
    "Then, we first train the discriminator by using backward_D method in which we feed the fake images produced by generator to the discriminator (make sure to detach them from the generator's graph so that they act as a constant to the discriminator, like normal images) and label them as fake. Then we feed a batch of real images from training set to the discriminator and label them as real. We add up the two losses for fake and real and take the average and then call the backward on the final loss.\n",
    "Now, we can train the generator. In backward_G method we feed the discriminator the fake image and try to fool it by assigning real labels to them and calculating the adversarial loss. As I mentioned earlier, we use L1 loss as well and compute the distance between the predicted two channels and the target two channels and multiply this loss by a coefficient (which is 100 in our case) to balance the two losses and then add this loss to the adversarial loss. Then we call the backward method of the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcjuQkPuU6tf"
   },
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "  def __init__(self, input_size=512*8*8, output_size=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(input_size, 1000)\n",
    "        self.fc2 = nn.Linear(1000, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.fc1(x)\n",
    "      return self.fc2(self.relu(x))\n",
    "\n",
    "class ColorizationHead(nn.Module):\n",
    "  def __init__(self, input_c=1, output_c=2, n_down=5, num_filters=512):\n",
    "        super().__init__()\n",
    "        self.model_layers = []\n",
    "        self.model_layers += (self.get_layer(num_filters, num_filters))\n",
    "        for _ in range(n_down - 5):\n",
    "            self.model_layers += (self.get_layer(num_filters, num_filters, dropout=True))\n",
    "        out_filters = num_filters\n",
    "        for _ in range(3):\n",
    "            self.model_layers += (self.get_layer(out_filters // 2, out_filters))\n",
    "            out_filters //= 2\n",
    "        self.model_layers += (self.get_layer(output_c, out_filters, outermost=True))\n",
    "        self.model = nn.Sequential(*self.model_layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "      return self.model(x)\n",
    "\n",
    "  def get_layer(self, nf, ni, bias=False, dropout=False, outermost=False):\n",
    "        layer = []\n",
    "        conv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
    "                                              stride=2, padding=1, bias=bias)\n",
    "        relu = nn.ReLU(False)\n",
    "\n",
    "        layer.append(relu)\n",
    "        layer.append(conv)\n",
    "\n",
    "\n",
    "        if outermost:\n",
    "          layer.append(nn.Tanh())\n",
    "        else:\n",
    "          layer.append(nn.BatchNorm2d(nf))\n",
    "\n",
    "        if dropout:\n",
    "          layer.append(nn.Dropout(0.5))\n",
    "\n",
    "        return layer\n",
    "\n",
    "class MLTModel(nn.Module):\n",
    "  def __init__(self, head=\"multitask\"):\n",
    "          super().__init__()\n",
    "          self.resnet_body = create_body(resnet18, pretrained=True, n_in=1, cut=-2)\n",
    "          for param in self.resnet_body.parameters():\n",
    "              param.requires_grad = False\n",
    "          self.heads = []\n",
    "          self.head = head\n",
    "          if head==\"multitask\":\n",
    "            self.classifier_head = ClassifierHead()\n",
    "            self.colorization_head = ColorizationHead()\n",
    "          elif head==\"classifier\":\n",
    "            self.classifier_head = ClassifierHead()\n",
    "          elif self.head==\"colorization\":\n",
    "            self.colorization_head = ColorizationHead()\n",
    "          else:\n",
    "              raise Exception('Invalid head')\n",
    "  def forward(self, x):\n",
    "      if self.head==\"multitask\":\n",
    "          x = self.resnet_body(x)\n",
    "          out_classifier = self.classifier_head(x.view(-1, 512*8*8))\n",
    "          out_colorization_head = self.colorization_head(x)\n",
    "          return out_classifier, out_colorization_head\n",
    "      elif self.head==\"classifier\":\n",
    "          x = self.resnet_body(x)\n",
    "          out_classifier = self.classifier_head(x.view(-1, 512*8*8))\n",
    "          return out_classifier\n",
    "      elif self.head==\"colorization\":\n",
    "          x = self.resnet_body(x)\n",
    "          out_colorization_head = self.colorization_head(x)\n",
    "          return out_colorization_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yXCkZn1Z6AO0"
   },
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n",
    "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "\n",
    "        if net_G is None:\n",
    "            self.net_G = init_model(MLTModel(), self.device)\n",
    "            print(self.net_G.parameters())\n",
    "        else:\n",
    "            self.net_G = net_G.to(self.device)\n",
    "        self.head = self.net_G.head\n",
    "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        self.class_criterion = nn.CrossEntropyLoss()\n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "\n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "\n",
    "    def setup_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.ab = data['ab'].to(self.device)\n",
    "        self.labels = data['class'].to(self.device)\n",
    "            \n",
    "            \n",
    "    def forward(self):\n",
    "        g_out = self.net_G(self.L)\n",
    "        if self.head==\"multitask\":\n",
    "            self.fake_color = g_out[1]\n",
    "            self.class_pred = g_out[0]\n",
    "        elif self.head==\"classifier\":\n",
    "            self.class_pred = g_out\n",
    "        elif self.head==\"colorization\":\n",
    "            self.fake_color = g_out\n",
    "        # print(f\"Class preds: {torch.argmax(self.class_pred, dim=1)}\")\n",
    "\n",
    "    def backward_D(self):\n",
    "        # print(f\"L shape: {self.L.shape}\")\n",
    "        # print(f\"self.fake_color shape: {self.fake_color.shape}\")\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "\n",
    "    def backward_G(self):\n",
    "        losses_list = []\n",
    "        if self.head in [\"multitask\",  \"colorization\"]:\n",
    "            fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "            fake_preds = self.net_D(fake_image)\n",
    "            self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "            self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "            losses_list.append(self.loss_G_GAN)\n",
    "            losses_list.append(self.loss_G_L1)\n",
    "\n",
    "        if self.head in [\"multitask\",  \"classifier\"]:\n",
    "            self.class_loss = self.class_criterion(self.class_pred, self.labels)\n",
    "            losses_list.append(self.class_loss)\n",
    "            max_pred = self.class_pred.argmax(dim=1)\n",
    "            self.class_accuracy = (max_pred == self.labels).sum()\n",
    "            # print(max_pred)\n",
    "            # print(self.labels)\n",
    "        \n",
    "        # self.loss_G = self.loss_G_GAN + self.loss_G_L1 + self.class_loss\n",
    "        self.loss_G = sum(losses_list)\n",
    "        self.loss_G.backward()\n",
    "\n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        if self.head!=\"classifier\":\n",
    "            self.net_D.train()\n",
    "            self.set_requires_grad(self.net_D, True)\n",
    "            self.opt_D.zero_grad()\n",
    "            self.backward_D()\n",
    "            self.opt_D.step()\n",
    "\n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC8Vu7Du6AO0"
   },
   "source": [
    "### 1.xx Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6tDAP966AO0"
   },
   "source": [
    "These functions were nor included in the explanations of the TDS article. These are just some utility functions to log the losses of our network and also visualize the results during training. So here you can check them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZahY3b9k6AO1"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.history_losses = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "\n",
    "    def update(self, val, count=1, acc=False):\n",
    "        if acc:\n",
    "            self.count += count\n",
    "            self.sum += val\n",
    "            self.avg = self.sum / self.count\n",
    "        else:\n",
    "            self.count += count\n",
    "            self.sum += count * val\n",
    "            self.avg = self.sum / self.count\n",
    "        self.history_losses.append(val)\n",
    "\n",
    "def clear_losses(loss_meter_dict):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss_meter.reset()\n",
    "        \n",
    "def create_loss_meters():\n",
    "    loss_D_fake = AverageMeter()\n",
    "    loss_D_real = AverageMeter()\n",
    "    loss_D = AverageMeter()\n",
    "    loss_G_GAN = AverageMeter()\n",
    "    loss_G_L1 = AverageMeter()\n",
    "    loss_G = AverageMeter()\n",
    "    class_loss = AverageMeter()\n",
    "    class_accuracy = AverageMeter()\n",
    "\n",
    "    return {'loss_D_fake': loss_D_fake,\n",
    "            'loss_D_real': loss_D_real,\n",
    "            'loss_D': loss_D,\n",
    "            'loss_G_GAN': loss_G_GAN,\n",
    "            'loss_G_L1': loss_G_L1,\n",
    "            'loss_G': loss_G,\n",
    "            'class_loss': class_loss,\n",
    "            'class_accuracy': class_accuracy}\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        try:\n",
    "            if loss_name == 'class_accuracy':\n",
    "                acc = True\n",
    "            else:\n",
    "                acc=False\n",
    "            loss = getattr(model, loss_name)\n",
    "            loss_meter.update(loss.item(), count=count, acc=acc)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    Takes a batch of images\n",
    "    \"\"\"\n",
    "\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n",
    "\n",
    "def visualize(model, data, save=True):\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.net_G.train()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "    fake_imgs = lab_to_rgb(L, fake_color)\n",
    "    real_imgs = lab_to_rgb(L, real_color)\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        ax.imshow(fake_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "        ax.imshow(real_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
    "\n",
    "def log_results(loss_meter_dict):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        if loss_name == 'class_accuracy':\n",
    "            print(f\"{loss_name}: {loss_meter.avg:.5f}%\")\n",
    "        else:\n",
    "            print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-1Tvniw6AO1"
   },
   "source": [
    "I hope this code is self-explanatory. Every epoch takes about 4 minutes on not a powerful GPU as Nvidia P5000. So if you are using 1080Ti or higher, it will be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780,
     "referenced_widgets": [
      "e59d6627f6574ba7b64b8ccb29ca0f95",
      "1922bcc9615442d9a73d27d40c174af4",
      "ba8215ec9e1349ad91148f0f81ca6186",
      "5d966ea139174200bdc8a79711f87ff8",
      "0ee4279c73194a51a6b8422eb869b145",
      "b378343c5ffe423fa77d531b8dd9bc36",
      "ac98114ef9f143eeb9ebe7d60512856c",
      "3bd8134a07fa4c5599e0ac5e22e3088e",
      "06047e45340041eb99eb5732cac164b1",
      "901ab7a2ee86435780836d8892184541",
      "4d402d704c784e1eabbaf4e075ff19a8"
     ]
    },
    "id": "sXTzut7Q6AO1",
    "outputId": "05906c50-dd34-4482-ad01-bf3dac07dc32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized with norm initialization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4351fd1b427e418b80887dd52a618de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "Iteration 20/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 2.86961\n",
      "class_loss: 2.86961\n",
      "class_accuracy: 0.57188%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 40/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 1.78711\n",
      "class_loss: 1.78711\n",
      "class_accuracy: 0.67031%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 60/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 1.39069\n",
      "class_loss: 1.39069\n",
      "class_accuracy: 0.71667%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 80/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 1.16857\n",
      "class_loss: 1.16857\n",
      "class_accuracy: 0.74844%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 100/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 1.01923\n",
      "class_loss: 1.01923\n",
      "class_accuracy: 0.76750%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 120/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.94642\n",
      "class_loss: 0.94642\n",
      "class_accuracy: 0.77500%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 140/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.88016\n",
      "class_loss: 0.88016\n",
      "class_accuracy: 0.78661%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 160/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.82874\n",
      "class_loss: 0.82874\n",
      "class_accuracy: 0.79180%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 180/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.79179\n",
      "class_loss: 0.79179\n",
      "class_accuracy: 0.79688%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 200/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.76229\n",
      "class_loss: 0.76229\n",
      "class_accuracy: 0.80188%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 220/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.72325\n",
      "class_loss: 0.72325\n",
      "class_accuracy: 0.80994%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 240/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.70343\n",
      "class_loss: 0.70343\n",
      "class_accuracy: 0.81328%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 260/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.67572\n",
      "class_loss: 0.67572\n",
      "class_accuracy: 0.81899%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 280/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.66296\n",
      "class_loss: 0.66296\n",
      "class_accuracy: 0.82076%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 300/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.64264\n",
      "class_loss: 0.64264\n",
      "class_accuracy: 0.82458%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 320/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.62987\n",
      "class_loss: 0.62987\n",
      "class_accuracy: 0.82695%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 340/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.62240\n",
      "class_loss: 0.62240\n",
      "class_accuracy: 0.82721%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 360/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.60726\n",
      "class_loss: 0.60726\n",
      "class_accuracy: 0.83090%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 380/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.59843\n",
      "class_loss: 0.59843\n",
      "class_accuracy: 0.83240%\n",
      "\n",
      "Epoch 1/1\n",
      "Iteration 400/407\n",
      "loss_D_fake: 0.00000\n",
      "loss_D_real: 0.00000\n",
      "loss_D: 0.00000\n",
      "loss_G_GAN: 0.00000\n",
      "loss_G_L1: 0.00000\n",
      "loss_G: 0.58762\n",
      "class_loss: 0.58762\n",
      "class_accuracy: 0.83406%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'net_G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m MainModel(net_G\u001b[38;5;241m=\u001b[39mMLTModel(head\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     22\u001b[0m model, loss_meter_dict \u001b[38;5;241m=\u001b[39m train_model(model, train_dataloader, \u001b[38;5;241m1\u001b[39m, display_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[43mnet_G\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict()))\n\u001b[1;32m     24\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(net_G\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mres18-unet.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(loss_meter_dict, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./loss_meter_dict.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net_G' is not defined"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_dl, epochs, display_every=200):\n",
    "    data = next(iter(val_dataloader)) # getting a batch for visualizing the model output after fixed intrvals\n",
    "    loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to\n",
    "    for e in range(epochs):\n",
    "        i = 0                                  # log the losses of the complete network\n",
    "        clear_losses(loss_meter_dict)\n",
    "        for data in tqdm(train_dl):\n",
    "            model.setup_input(data)\n",
    "            model.optimize()\n",
    "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n",
    "            i += 1\n",
    "            if i % display_every == 0:\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
    "                log_results(loss_meter_dict) # function to print out the losses\n",
    "                if model.head!=\"classifier\":\n",
    "                    visualize(model, data, save=False) # function displaying the model's outputs\n",
    "    return model, loss_meter_dict\n",
    "\n",
    "model = MainModel(net_G=MLTModel(head=\"classifier\"))\n",
    "\n",
    "model, loss_meter_dict = train_model(model, train_dataloader, 1, display_every=20)\n",
    "\n",
    "# Saving\n",
    "torch.save(net_G.state_dict(), \"res18-unet.pt\")\n",
    "torch.save(loss_meter_dict, \"./loss_meter_dict.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDqwckZ06AO1"
   },
   "source": [
    "Every epoch takes about 3 to 4 minutes on Colab. After about 20 epochs you should see some reasonable results."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06047e45340041eb99eb5732cac164b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ee4279c73194a51a6b8422eb869b145": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1922bcc9615442d9a73d27d40c174af4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b378343c5ffe423fa77d531b8dd9bc36",
      "placeholder": "​",
      "style": "IPY_MODEL_ac98114ef9f143eeb9ebe7d60512856c",
      "value": "  1%"
     }
    },
    "3bd8134a07fa4c5599e0ac5e22e3088e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d402d704c784e1eabbaf4e075ff19a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d966ea139174200bdc8a79711f87ff8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_901ab7a2ee86435780836d8892184541",
      "placeholder": "​",
      "style": "IPY_MODEL_4d402d704c784e1eabbaf4e075ff19a8",
      "value": " 4/500 [02:25&lt;4:19:11, 31.35s/it]"
     }
    },
    "901ab7a2ee86435780836d8892184541": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac98114ef9f143eeb9ebe7d60512856c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b378343c5ffe423fa77d531b8dd9bc36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba8215ec9e1349ad91148f0f81ca6186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bd8134a07fa4c5599e0ac5e22e3088e",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06047e45340041eb99eb5732cac164b1",
      "value": 4
     }
    },
    "e59d6627f6574ba7b64b8ccb29ca0f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1922bcc9615442d9a73d27d40c174af4",
       "IPY_MODEL_ba8215ec9e1349ad91148f0f81ca6186",
       "IPY_MODEL_5d966ea139174200bdc8a79711f87ff8"
      ],
      "layout": "IPY_MODEL_0ee4279c73194a51a6b8422eb869b145"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
